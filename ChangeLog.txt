Release Notes

* 5/25/2022
  * 0.0.30 for containerization

* 2/18/2020
  * added use_only_local_data

* 11/12/2019
  * 0.0.23
  * fixed for wheel

* 11/8/2019
  * 0.0.22
  * enabled wheel
  * fixed for pip+virtualenv

* 11/7/2019
  * 0.0.21
  * added python 2/3 compatibility
  * added pip and virtual env support

* 9/3/2019
  * token-based auth

* 8/26/2019
  * changed sub dataset names
  * changed heartbeat timeout to be configurable

* 8/22/2019
  * removed zero padding in _sub
  * using only 5 digits in SUBCOUNTER_SUBID_SEQ

* 8/21/2019
  * taking ddm blacklist into account for site inputs

* 4/23/2019
  * supplemental error for lost-heartbeat jobs

* 4/10/2019
  * added memory_leak to jobs

* 4/2/2019
  * added fullFlag in getJediTasksInTimeRange

* 3/26/2019
  * using supError* for invalid batchID
  * using supError* for worker's error reporting

* 3/15/2019
  * added express for task.currentprio>=1500

* 3/11/2019
  * added fake in specialHandling

* 2/28/2019
  * added useZipToPin

* 2/18/2019
  * to set nEvents to zip

* 2/12/2019
  * enhanced getOfflineRunning for analy

* 2/5/2019
  * not to reassign throttled jobs
  * not to throttle short jobs

* 2/1/2019
  * added checkFailureCountWithCorruptedFiles

* 1/29/2019
  * added es_toolong

* 1/25/2019
  * added corrupted events

* 1/18/2019
  * checking batchID in updateJob

* 12/21/2018
  * to reduce attempts for esmerge

* 12/19/2018
  * to change MCORE to SCORE for small ES jobs

* 12/5/2018
  * to take into account objstoreIDs of zip files when making esmerge

* 11/14/2018
  * one sub per job for ART

* 10/30/2018
  * added list_ptest_prod_sources

* 10/22/2018
  * added proc_status
  * sending ioIntensity
  * fixed ppE for maxAttempt

* 10/16/2018
  * added decAttOnFailedES

* 10/5/2018
  * added discardEvents in retryTask

* 9/26/2018
  * added grace_period in eraseDataset

* 9/25/2018
  * moved file lock from getEvents to ppE

* 9/7/2018
  * added scattered in getEventRanges

* 7/24/2018
  * added rc_test2

* 7/23/2018
  * added reloadInput

* 7/16/2018
  * fixed recoverLostFiles to update nEvents in input and output datasets

* 6/19/2018
  * added noChildRetry to recoverLostFiles

* 6/18/2018
  * added hasReadyEvents

* 6/13/2018
  * added harvester_slots

* 6/10/2018
  * added useBrokerOff in catchall

* 5/30/2018
  * enabled aggressive heartbeat check

* 5/23/2018
  * added transpath to global share

* 5/22/2018
  * added guid check in Adder

* 5/18/2018
  * added EC_WorkerDone

* 5/17/2018
  * added syncLevel to updateWorker

* 5/8/2018
  * added getJobStatisticsPerSiteResource

* 5/7/2018
  * schedconfig.capability

* 4/25/2018
  * improved getSitesShareDDM to reflect new endpoint association

* 4/10/2018
  * added updateJobsInBulk

* 4/9/2018
  * added nJobs and computingElement to workers

* 4/6/2018
  * added sj
  * fixed getJobs for notDiscardEvents

* 3/28/2018
  * added harvester_dialogs

* 3/20/2018
  * not to discard events

* 3/16/2018
  * reset stateChangeTime for retried es merge
  * to avoid himem for es merge

* 3/15/2018
  * input files in ZIP_MAP
  * changed ordering of event ranges

* 3/15/2018
  * fixed Freezer not to close sub datasets if resurrected consumer could use them
  * moved from astorages0 to astorages (AGIS request)

* 3/13/2018
  * fill HS06sec for jobs without task (e.g. HC)

* 3/12/2018
  * fixed ppE to reset more attributes
  * changed RSE for _sub of ES jobs

* 2/28/2018
  * changed command messages to INFO

* 2/23/2018
  * added a protection against non-integer transExitCode
  * added a protection not to close dis datasets if resurrected consumer could use them
  * changed ppE not to resurrect consumers killed in defined

* 2/20/2018
  * changed --keepUnmerged to kill jobsets if no events got started

* 2/16/2018
  * added more info when dispatchDBlock failed

* 2/15/2018
  * changed get/updateEvents to take local pilot owner into account

* 2/6/2018
  * locking job in active4 when ppE and getEvents

* 2/2/2018
  * fixed resurrect consumers for consumers killed in assigned

* 1/25/2018
  * added comprehensive heartbeat

* 1/22/2018
  * added es_preempted

* 1/18/2018
  * added checkEventsAvailability

* 1/15/2018
  * added nStandby

* 1/8/2018
  * using keepUnmerged to reassign jobs
  * to kill all consumers when a consumer is killed

* 12/6/2017
  * changed to avoid reattempts of ES jobs when jobseed is std or status is not online or brokeroff

* 11/29/2017
  * changed JD to allow xml=json

* 11/24/2017
  * added a hint to (un)throttle users
  * disabled OracleEI for https://cern.service-now.com/service-portal/view-incident.do?n=INC1529405

* 11/21/2017
  * allowing incexec for exhausted

* 11/20/2017
  * Using AES_MINEVENTSFORMCORE = max(AES_MINEVENTSFORMCORE, schedconfig.corecount)

* 11/10/2017
  * Changed HS06sec formula to actualcorecount * corepower * duration

* 11/8/2017
  * setting jobsetID in JEDI_Dataset_Contents
  * using separate site attribute for jobseed

* 11/1/2017
  * sending ES consumers to SCORE if there are not enough events
  * added harvester_id and worker_id in getJobs

* 10/10/2017
  * updated hint in getJobs

* 10/09/2017
  * setNoRetry to update also files in running status
  * added usePrefetcher

* 10/06/2017
  * added PQ.status=paused

* 10/05/2017
  * DDMSpec.getAssociatedEndpoint choosing endpoint with lowest order

* 10/02/2017
  * enabling TEST and SPECIAL endpoints

* 9/27/2017
  * added resurrectConsumers

* 9/26/2017
  * using DATADISK for analysis staging-in

* 9/12/2017
  * locking a file in getEventRanges

* 8/30/2017
  * metadata registration for ES files

* 8/17/2017
  * added registerEsFiles
  * changed AdderAtlas to catch InvalidRSEExpression

* 8/15/2017
  * removed sleep in copyArchive
  * removed FOR UPDATE when counting events for now

* 8/9/2017
  * fixed ppE to exclusively count num of unprocessed events

* 8/8/2017
  * improved setMerge to try local if remote is unavailable
  * fixed ppE to keep job status when old job is closed in jobsDefined/Waiting
  * improved ppE to take unifiedPQ into account
  * fixed ppE to set resource_type to merge

* 7/26/2017
  * setting cancelled/failed to es_killed/es_aborted
  * not to kill consumers in inactive sites when associated consumers are active

* 7/25/2017
  * added protection against duplicated submission by group users
  * added blank pilots to harvesterCtl

* 7/17/2017
  * changed ES merge to choose sites with wnconnectivity

* 7/12/2017
  * added background and resourceType in getJob
  * setting background-able flag

* 7/10/2017
  * added command_lock stuff

* 7/6/2017
  * added tighter isolation for check of concurrent running consumers

* 7/3/2017
  * added checkJobStatus

* 6/29/2017
  * added reportWorkerStats and harvesterCtl

* 6/26/2017
  * WQ-GS alignment

* 5/26/2017
  * fixed killJob with keepUnmerged not to discard evens
  * changed SetupAtlas to make _sub when esMergeOnOS is used

* 5/23/2017
  * changed retryJob to reset computingSite to ES merge jobs

* 5/17/2017
  * introduced timeout for throttled jobs
  * changed ES merge to avoid jobseed=es

* 5/8/2017
  * added nSimEvents
  * changed managed to fail when nevents is not set

* 5/3/2017
  * fixed eventStatus=merged for objStore_ID=None

* 5/2/2017
  * added unified PQs
  * added inFilePosEvtNum
  * fixed ppE not to duplicate ES merge jobs

* 4/25/2017
  * fake co-jumbo
  * added path_convention

* 4/24/2017
  * resource_type tagging

* 4/18/2017
  * added subDeleter

* 4/14/2017
  * added noExecStrCnv

* 4/6/2017
  * zip outputs

* 3/20/2017
  * fixed increaseAttemptNr for maxAttempt<attemptNr

* 3/15/2017
  * changed propageR to trigger recalculation of task params based on nDone

* 3/14/2017
  * removed SE check in Adder

* 2/16/2017
  * added getProxy
  * changed killTask.py not to kill holding by default

* 2/10/2017
  * added DBProxyFiltered

* 2/6/2017
  * Protection against undef

* 2/3/2017
  * using schedconfig.dn to specify pilot owners

* 2/2/2017
  * added columns for new memory monitor

* 1/30/2017
  * fixed EiOra for empty streamName
  * fixed updateEventRanges

* 1/27/2017
  * removed dq2 dependency

* 1/23/2017
  * added CAP_RUNNING_USER_JOBS

* 1/11/2017
  * fixed fingers for RFC proxy

* 12/15/2016
  * added mergeEsOnOS
  * using new filename format for ES merge for rel20 or higher

* 12/2/2016
  * changed to update stateChangeTime properly

* 12/1/2016
  * removed retry for analysis in Watcher

* 11/25/2016
  * added pilot_killed

* 11/24/2016
  * Updated MySQL DB schema

* 11/18/2016
  * added task_id and account to prestaging rules

* 11/14/2016
  * made timeout value for analysis rebrokerage configurable
  * added maxWalltime to getJob response

* 11/11/2016
  * removed dependencies on se, seprodpath, setokens in schedconfig

* 11/10/2016
  * added recoverLostFiles

* 11/2/2016
  * added es_heartbeat and es_merge_failed

* 10/31/2016
  * disabled ES file registration
  * fixed del flag for failed ES merge jobs

* 10/28/2016
  * fixed localEsMergeNC

* 10/27/2016
  * changed rebro to kill starting jobs
  * changed starting jobs not to update modification time

* 10/20/2016
  * reduced timeout for activated user jobs to 6h from 24h

* 10/18/2016
  * jedi_events.error_code
  * jobsubstatus=pilot_finished

* 10/17/2016
  * allowing cancelled jobs to register log files

* 10/15/2016
  * eventStatus=fatal

* 9/20/2016
  * checking sutck merging jobs

* 9/16/2016
  * setting DEL flag to event ranges

* 9/15/2016
  * added tier to SiteSpec

* 9/12/2016
  * added multi zip support for ES

* 9/7/2016
  * using soft erase for dis and sub
  * adding all production sites to WORLD by default

* 8/29/2016
  * added accesptJson to get/update event ranges

* 7/28/2016
  * using w instead of d to get OS info

* 7/25/2016
  * tagging of shares
  * removed obsoleted memcached code

* 7/14/2016
  * using bulk fetch for files in storeJobs

* 7/12/2016
  * registering and deleting ES files in rucio

* 7/8/2016
  * added jumbo job stuff

* 7/1/2016
  * changed Savanna to JIRA in notifications
  * fixed killUnfinishedJobs

* 6/28/2016
  * added a protection to DyPD2P for large user datasets

* 6/23/2016
  * added avalancheTask
  * fixed Watcher to correctly change jobParams for pmerge

* 6/21/2016
  * fixed datasetMgr to delete dis for panda.um

* 6/20/2016
  * more informative message for closed clones

* 6/13/2016
  * added keepUnmerged to killJob
  * removed datatype check from EP

* 6/7/2016
  * changed to sort files for ES since file order is important for positional event number

* 6/6/2016
  * resetting batchID for retry

* 6/2/2016
  * removed scope from tmpin

* 5/31/2016
  * fixed event range generation with multiple inputs

* 5/20/2016
  * added a protection against unique constraint ATLAS_RUCIO.DIDS_GUID_IDX violation
  * added a protection against too long scope
  * setting panda_id and campaign to file metadata

* 5/25/2016
  * imporved getJediTaskDetails
  * added writeInputToFile
  * fixed Watcher for time-outed ES merge not to update ES jobs

* 5/9/2016
  * reduced memory consumtion and removed redundant file lookups in SetupperAtlas

* 5/4/2016
  * changed to copy ES merge trf to job.transformation
  * changed ES jobs to go from merging to failed when associated ES jobs go to failed

* 5/3/2016
  * using merging for ES jobs while ES merge is running

* 5/2/2016
  * changed AdderAtlas to work without srm endpoints with OS endpoint
  * added localEsMergeNC

* 4/28/2016
  * changed getJob to send json if clients accept it

* 4/17/2016
  * fixed killUnusedEvent* to check jobsetID

* 4/13/2016
  * fixed insertTaskParam to update JEDI taskparam table when task is running
  * fixed listDatasetByGUIDs to regard UnknownDatasetException as fatal

* 4/11/2016
  * changed to accept retry(newOpts) when analy tasks are running
  * changed getJob for retried ES merge jobs
  * fixed double counting in getCriteria 

* 4/10/2016
  * changed propageResult for cloned jobs to set jobset_id

* 4/8/2016
  * setting destinationse for log of ES merge

* 4/7/2016
  * changed not to send ES merge to short queue
  * changed not to send log info to ES merge
  * using -details richtype for EI
  * recording jobsetIDs and their history for ES

* 4/6/2016
  * fixed fairshare for WORLD
  * introduced connection pool for EI lookup

* 4/5/2016
  * fixed updateUnmergeDS for running
  * changed submitJobs to require FQANs for atlas
  * fixed ppE to use sites with corecount=null when looking for score
  * fixed killUnusedESC to kill running consumers when killAll
  * added prod role check in submitJob

* 4/4/2016
  * fixed nucleus.getAssoicatedEndpoint for dst:

* 4/1/2016
  * changed updateRelatedEventServiceJobs to update stateChangeTime

* 3/31/2016
  * added Oracle EI stuff

* 3/24/2016
  * fixed getEventRanges to kill unused consumers if no more events

* 3/23/2016
  * fixed cloned jobs to set pandaIDs in Dataset_Contents
  * added changeTaskModTimePanda and triggerTaskBrokerage
  * fixed AdderAtlas for RSEProtocolNotSupported
  * added checkClonedJob
  * changed localEsMerge to send merge jobs to score

* 3/21/2016
  * changed checkTaskStatus to allow updates in exhausted
  * fixed retryJob not to add metadata
  * fixed ES merge retry to take attemptNr into account
  * fixed killESC for multiple inputs
  
* 3/18/2016
  * resetting ramCount to 0 for ES merge

* 3/16/2016
  * added putLogToOS
  * added newParams in retryTask
  * changed dispatcher to ignore fairshare for ES merge

* 3/14/2016
  * introduced jobSubStatus=pilot_closed

* 3/10/2016
  * added isSuperUser

* 3/9/2016
  * added changeTaskSplitRule
  * added changeTaskAttribute
  * fixed ppEvt for nucleus without localEsMerge
	
* 3/8/2016
  * fixed to properly decrease priorities for group analysis

* 3/7/2016
  * using is_local in DdmSpec

* 3/2/2016
  * changed retryTask for running tasks to reactivate failed inputs

* 2/29/2016
  * fixed updateForPilotRetryJEDI to update outPandaID

* 2/25/2016
  * changed SiteSpec.isDirectIO to take direct_access_lan into account

* 2/23/2016
  * added getAssoicatedEndpoint to DdmSpec

* 2/22/2016
  * added allowWanInputAccess

* 2/19/2016
  * setting jobSubStatus to upstream jobs when merge is failed

* 2/18/2016
  * fixed getCriteria for groups without wildcards

* 2/17/2016
  * added getDispatchDatasetsPerUser

* 2/16/2016
  * using datasets.currentfiles to store dis size

* 2/15/2016
  * using 14days lifetime for panda rules
  * added altStgOut

* 2/12/2016
  * changed NucleusSpec to ignore SPECIAL
  * added protection against space_*=None
  * added softkill for ES preemption
  * using asynchronous rules for GEN dis

* 2/9/2016
  * added mode to reassignTaskTo*
  * added file check for assigned jobs
  * changed HC DN for glexec

* 2/8/2016
  * added esPreemption

* 2/4/2016
  * added nucleus and eventService to jobSpec

* 2/3/2016
  * changed retryTask so that failed jobs in pending/running/scouting tasks can be retried

* 2/1/2016
  * added reassignTaskToNucleus

* 1/29/2016
  * changed to allow satellites in destinationSE

* 1/28/2016
  * setting nucleus to destinationSE

* 1/27/2016
  * removed __str__ in DdmSpec

* 1/26/2016
  * added getDNsForS3
  * added protection not to change failed jobs to holding

* 1/25/2016
  * sending objStoreIDs for ES merge
  * added network configurator and corepower collection

* 1/19/2016
  * changed addMetaData to limit the size of json for failed jobs

* 1/18/2016
  * changed to update status of ES jobs when ES-merge is done
  * enabled a protection for transferring->holding and holding->holding with final heartbeats

* 1/12/2016
  * changed AdderAtlas for alternative stage-out
  * added objstoreID to updateEventRange
  * changed eventLookupClientEI to use new EI client

* 1/11/2016
  * changed killJob so that 51 goes forward even if commandToPilot was already set

* 1/5/2016
  * using DISK for prestaging

* 12/28/2015
  * fixed updateUnmerged so that merging jobs fail only when max attempt is reached

* 12/15/2015
  * removed redundant log sending
  * added days to getScriptOfflineRunning
  * fixed dispatcher to release lock in finally

* 12/12/2015
  * killing pending jobs in small chunks to avoid timeout
  * added protection in panda.py for cgi exception

* 12/9/2015
  * changed AtlasAdder so that jobs don't go to transferring if only log
  * removed panda_ddm_relation

* 12/8/2015
  * fixed input duplication check for multiple consumers
  * using DISK for tape prestaging for analysis

* 12/7/2015
  * inroduced jobStatus=closed
  * changed Adder to send notification when --destSE doesn't work


* 12/2/2015
  * added a protection in insertNewJob to avoid duplicated input usage

* 11/30/2015
  * added a protection for late insert of metadata

* 11/26/2015
  * added jobStatus=closed
  * changed Nucleus to remove ATLAS when getting endpoint with spacetoken

* 11/23/2015
  * fixed pseudo files in propagateResult

* current
  * added max/minrss
  * using std by default for jobSeed
  * changed not to reset nooutput when pmerge is done
  * fixed getSiteSpecs not to propagate ddm endpoints to clients
  * added nucleus stuff
  * improved error message when pilot produced a wrong file
  * added changeTaskCputime
  * using Express for urgent or high prio input
  * checking metadata before closing sub datasets to avoid a rucio bug
  * fixed datasetMgr to avoid lookup for nonexistent datasets
  * fixed datasetMgr to take distributed dataset into account
  * fixed for internal merge + zero suppression
  * changed AdderGen and AdderAtlas to treat missing files more properly
  * added allowNoOutput
  * improved checkInputFiles
  * changed copyFileRecord to update JEDI files too
  * diabled inputFileCheck in Adder for pilotRetry
  * fixed propageteResult for killed merging after pmerge incremented attemptNr
  * added RSENotFound
  * patched AdderAtlas for MWT2 PRODDISK
  * added dynamicNumEvents stuff
  * changed checkTaskStatus
  * changed copyFileRecord to work with original or w/o original
  * changed regexp to look for unmerged files 
  * registring location for GEN
  * fixed user group accounting for mergeOutput
  * capping number of running user jobs 
  * changed fairshare to work with HS06
  * removed exception in fairshare so that T1 uses cloud.fairshare if empty
  * added ESMERGERECOVERABLE. Eventually should be taken care of by retrial module
  * added giveGUID to EventPicking
  * changed hint for JEDI_Events
  * added some ES error codes
  * updating nEventsUsed only for input datasets
  * added CloserAtlasPlugin
  * initializing DBProxy._logger when importing module since resetting in JediDBProxy was broken 
  * added machinery to leave files where they are produced
  * using Express for urgent or prio>1000
  * added NOWAIT in killEventServiceConsumers
  * added NOWAIT in killJob
  * added validation check for pmerge 
  * added disableFurtherAttempt not to retry killed pmerge
  * added hint for JEDI_Events
  * using executemany to insert event ranges
  * fixed retryJob for ES merge
  * added WORLD
  * removed rse from registerNewDataset for _sub
  * fixed ppEvent not to generate merge jobs when there are failed events in another process
  * setting rule lifetime to hc_test,install,gangarbt
  * changed SA not to pin replicas at LOCALGROUP etc
  * setting activity for registerDatasetLocation
  * refreshing fairshre table every 15min
  * using group account for group.* with destSE
  * using "User Subscriptions" for user's rules
  * changed the limit to reassign jobs at inactive sites to prio=800
  * sending tobekilled to updateJob for already killed jobs
  * fixed bulk getJob for user jobs
  * changed ppEvt to keep failed event records for ES
  * changed getCriteriaForProdShare for urgent to ignore fairshare
  * added nJobs in getJob
  * removed datri stuff from EP
  * added hasValueInCatchall
  * keep records in SiteData for 48h
  * changed to reassign high prio jobs in activated/starting when sites are inactive
  * changed lastStart to be updated only by managed/user/panda
  * using rucio in getScriptOfflineRunning
  * removed registerDispatchDatasetLocation
  * changed to retry ES merge when lost heartbeat
  * added convertRSE for PRODDISK retirement
  * added updateEventRanges
  * using rucio API instead of DaTRI
  * updating lastStart
  * id in fairshare
  * added taskID to getJob
  * introduced prio limit in shares with throttled
  * changed code=51 to force-kill
  * fixed ppEvent for catchall=None
  * added more debug info to insertDataset
  * added soft flag to reassignTask
  * removed old hint for 10.2.0.4
  * added job cloning stuff
  * added max/avgRSS etc
  * resetting startTime to endTime when starting jobs are killed
  * removed pinning for panda.um
  * changed Setupper not to make redundant rule for panda.um
  * reduced timeout for high prio holding jobs
  * added -info to eventLookupClientEI
  * changed dispatcher to send DDM endpoints
  * added jediTaskID in getEventRanges
  * set file status to failed when consumers are killed
  * improved eventLookupClientEI for 0 matching
  * changed EventPicking to use EI
  * reduced timeout for lost-heartbeat to 2h from 6h
  * using tape replicas at T1
  * added 51 in killJob
  * added shareMgr.py
  * setting activity for _dis and _sub
  * reduced interval for low prio jobs to finish
  * fixed offlineRunning
  * setting a very large priority to ES merge jobs
  * reset doing datasets to kick updateUnmergedDatasets
  * setting hidden metadata to _dis/_sub
  * changed AdderAtlas to regard InvalidPath as fatal
  * changed TA to ignore clouds with mcshare=0
  * added exhausted
  * fixed getScriptOfflineRunning for ATLASPANDA-185
  * Added ALICE-Titan client scripts under test/alice/
  * Added LSST client scripts under test/lsst/
  * introduced maxFailuer in JEDI_Dataset_Contents
  * changed to use list_dataset_replicas of Rucio API
  * added support for valiable number of outputs
  * changed updateJobStatus to pin waiting consumers
  * fixed to update file status when jobs are timed out when aCT is transferring files
  * added localEsMerge
  * sorting datasetIDs to avoid dead-lock
  * added NOWAIT to updateJobStatus
  * fixed reassignTask.py
  * setting proper jobDefID when attemptNr>1 as well
  * adding NOWAIT to finalizePendingJobs
  * improved error message of getScriptOfflineRunning
  * fixed ppEventServiceJob not to update modTime for file and jobO
  * changed TA to work with mcshare(TW)=0
  * added a protection to EP for missing replica metadata
  * changed timeout for staring to 48h
  * changed getOriginPandaIDs to return only one origin
  * changed timeout for starting jobs to 12h
  * changed to keep endTime when jobs are killed
  * changed to ignore heartbeats when job is in merging
  * checking job status in updateEventRange
  * using Production Input/Output as subscription activities
  * recording throttled into jobs_statuslog
  * changed the task brokerage to use negative weight based on missing input size
  * fixed propagateResult for pmerge to update T_TASK.total_events 
  * changed TA to use sites where data is fully or partially available
  * removed old machinery to reassign reprocessing jobs
  * changed killUnusedEsConsumers to kill running jobs as well
  * cleanup in taskBuffer
  * added checkInvalidCharacters
  * added olderThan to reassignSite
  * changed reaper to expired
  * cleanup of the brokerage
  * fixed reassignSite for options
  * using stateChangeTime for heartbeat check of starting jobs
  * changed starting jobs not to be updated by subsequent heartbeats 
  * using panda instead of user account in EP
  * removed setReplicaMetaDataAttribute from EP
  * added partial finish
  * setting None to pre-merged log files when sending ES merge jobs
  * added protection to SetupperAtlas against new files copied after JEDI file lookup
  * fixed EventPicking to use only complete replicas
  * removed constraint with T1 data from TA
  * added soft finish
  * using ignore_availability when making subscriptions
  * making _dis w/o source when missing at T1
  * fixed ES retry
  * changed not to use pre-merged log files from failed jobs
  * changed TA to use old=True for listDatasetReplicas
  * sending sourceSite to the pilot
  * UnsupportedOperation as fatal 
  * channged getJob to ignore fairshare for pmerge
  * registering LB info to log
  * changed for jobName
  * added recordRetryHistory in insertNewJob
  * filling outPandaID
  * using rucio API for file registration
  * fixed rebro for jobDef=0
  * fixed rebro for defined
  * changed TA to take secondary volume into account
  * fixed TA for dataset aggregation
  * fixed reassignSite
  * added increaseRamLimitJEDI
  * fixed lockJobsForReassign
  * added killUnfinishedJobs
  * fixed retryJob for pseudo_input
  * fixed cyclic import in panda_config
  * fixed for UNDEFINED in jobReport.json
  * sending prodDBlocks to the pilot
  * changed updateJob to avoid row lock contantation
  * setting subJobStatus to cancelled ES jobs
  * extracting # of events from json
  * fixed getFreeDiskSize in PD2P
  * added retry for ES merge when ERR_ESMERGERECOVERABLE
  * fixed getScriptOfflineRunning for did
  * fixed killJob for ES
  * chnaged Setupper for InvalidRSEExpression
  * changed Adder to extract important DDM error messages
  * setting lifetime to _dis
  * added throttled
  * changed for originpandaid
  * changed event-picking to work with non deterministic URLs
  * introduced EventServiceLastUnprocessed
  * added reqID
  * fixed increaseAttemptNr to increase max attempt for secondary datasets
  * fixed to increment nFilesUsed when merging is killed before merge generation
  * added protection against orphaned merge jobs
  * using rucio api for _dis
  * fixed event-picking for rucio
  * fixed DDM for unicode
  * introduced timeout for starting
  * added increaseAttemptNr
  * fixed checkRucioDataset
  * fixed method emulator in DDM
  * changed to work with rucio containers 
  * cleanup to work without specialHandling=ddm:rucio
  * added protection against empty RSE Expression
  * using nevents=null for log files
  * ReplicaNotFound as a fatal error
  * using rucio when backEnd is None
  * added protection to AdderAtlas for uncatchable exceptions
  * fixed getJob for input log files of ES merge
  * moved analysis tape rebro from copyArchive to runRebro
  * considering high prio before mcore in the brokerage
  * forcing ddmBackEnd=rucio for anal tasks
  * changed for maxAttemptES
  * enabled ES merging
  * using force_backend=dq2 when backend is unspecified
  * fixed for pauseTask and resumeTask
  * fixed updateUnmergedDatasets to count nFiles in Contents
  * fixed AdderAtlas to take groupdisk into into account for registerFiles
  * added pauseTask and resumeTask
  * making GEN dis when input is in DQ2 even if ddm:rucio
  * updating nEvents when updateEventRange
  * reset jobSubStatus and jobMetrics in retried ES jobs
  * disabled updating nFilesOnHold in updateJob by transferring pmerge
  * using new eventlookup client
  * check sub to reduce nFilesOnHold when merging is killed
  * added protection to updateUmergeDataset to avoid concurrent update
  * disabled updating nFilesOnHold by transferring for trn_*
  * fixed Closer to update dataset status after unmerge datasets are updated
  * removed priority reduction for ES retry
  * changed datasetManager to kick stalled merging jobs
  * fixed killUnusedEventServiceConsumers not to kill running consumers
  * added toreassign to the list of active task status
  * added --prodSourceLabel to killTask
  * fixed fileCallbackListener to use TSL instead of sslv3
  * extracting LB Nr
  * changed panda.py to measure execution time for each call
  * using FileCatalogException as a fatal error for now
  * filling job summary fields for prod_test
  * changed ActiveMQ broker
  * changed to allow users to send prestaging requests to DDM
  * fixed getJob for esmerge to send only successful logs
  * added a protection to reassign JEDI jobs in defined
  * added a protection to AdderGen against esmerge xml
  * fixed es merge job generation
  * changed messages for finished by callback or catalog check
  * introducing multiporcesssing in add.py
  * kill instead of reassign in copyArchive
  * sending jediTaskID to the pilot for anal jobs
  * changed array limit in getEventRanges
  * added FinishedJobsByCallback/Catalog to SLS 
  * fixed EventPicker for fatal errors
  * fixed ES retry for failed jobs
  * reduced interval for catalog check to 4h  
  * introduced --eventPickSkipDaTRI
  * updating task status when EventPicker failed
  * making EventPicker log available to users
  * parsing DN when setting owner in EventPicker
  * reduced sleep interval in AdderAtlas
  * fixed datasetMgr not to delete _sub at dst:
  * fixed location registration for _sub + dst:
  * added updateFailedJobs in SetupperPluginBase
  * extended proxy cache for HPC
  * added changeTaskRamCount and changeTaskWalltime
  * fixed pilot retry to reset endTime error dialog
  * fixed nFilesOnHold for killed merging jobs
  * added protection to AdderGen against immediate XML reading
  * added eventPickNumSites
  * added protection against multiple updateUnmergeDataset calls
  * allowing to use non-T1 SE as destination
  * enabled the rebrokerage for ganga jobs
  * fixed insertTaskParamsPanda for analysis submission with prod role
  * fixed typo in killEventServiceConsumers and killUnusedEventServiceConsumers
  * changed to allow retry of failed analysis jobs while the task is still running
  * changed insertTaskParams to work with duplicated task names
  * added protection to MsgWrapper
  * increased timeout value for EP
  * improved TA to aggregate container
  * fixed pilot retry for pmerge
  * replacing $JEDITASKID
  * extracting sourceURL when fixedSandbox
  * added fixedSandbox
  * fixed panda_proxy_cache.py
  * removed NOWAIT from finalizePendingJobs
  * added protection when NOWAIT error happens in finalizePending
  * extracting nFiles and nEvents for incexec
  * added DataServiceUtils.getSitesShareDDM
  * added firstSubmission to Setupper
  * extracting more params for incexec
  * fixed getJediTaskDetails
  * fixed retryJob to check attemptNr in JEDI
  * setting retry in retry history
  * changed to use comm_parameters
  * changed to allow reactivation of aborted tasks
  * fixed insertTaskParamsPanda
  * changed propagateResultToJEDI to avoid row contention
  * fixed to kill jobs in merging
  * fixed runRebro for JEDI analysis
  * added jediTaskID and datasetID in the where clause of updateUnmergedJobs
  * setting maxattempt when JEDI files are produced
  * added protection against too long modification host
  * using failedAttempt
  * fixed file counting to merge failed jobs
  * changed the brokerage to get all file replicas first 
  * introduced 2h of timeout for transferring user jobs
  * added proxyCache
  * added -m to reassignTask
  * including _\d+$ in hospital queues
  * using bps in getWanDataFlowMaxtrix
  * using name instead of dn for specialDispatchParams
  * added avalage file lookup time in SLS
  * added getKeyPair
  * add timing info in broker_util
  * added retryTask() to Client
  * added check_pidfile in apache-ctl	
  * using HTTP instead of HTTPS for DDM callbacks 
  * fixed SetupperAtlas to ignore DQFrozenDatasetException when making _dis
  * added support for multiple ES consumer
  * changed changeTaskPriority to propagate changes to jobs too 
  * fixed dataset lookup by file GUID to allow wildcard search
  * changed to send input/output map to the pilot for ES merge
  * removed old TAPE check for BNL from brokerage
  * disabled PandaMover for US
  * changed Adder to register log files for ES
  * changed the protection for un-formatted HC destinationDBlock
  * added setDebugMode.py
  * added a protection against un-formatted destinationDBlock for HC	
  * using specialHandling=eventservice
  * changed Setupper to have a plugin structure
  * changed the brokerage to use CVMFS check for nightlies
  * added reassignTask
  * fixed jedi_events.endEvent
  * added a build number to version name
  * added cpuConsumptionTime to updateEventRanges
  * improved format of specialHandling for ES
  * adde actualCoreCount
  * improved to update t_task.total_events
  * fixed keepJob to append attemptNr correctly
  * disabled pandamover for AGLT2
  * removed updateFileMetadataInJEDI
  * added a protection against old JEDI jobs w/o fileIDs
  * changed to update nEvents in JEDI tables
  * changed to update total_req_jobs in t_task
  * changed the brokerge to use wildcard matching for ROOT
  * fixed the brokerage for bulk file lookup
  * fixed the brokearge to accept CVMFS ROOT version format
  * fixed the brokerage to use correct catalog for file lookup
  * set array size in setGUID
  * reseting computingElement for rebrokerage
  * giving higher priorities to pmerge
  * added WAN throttling
  * fixed reassignSite
  * sending coreCount to the pilot
  * fixed AdderAtlas for rucio
  * fixed for Rucio migration
  * updating t_task.total_done_jobs
  * changed killTask and finishTask to return a proper error code
  * removed reqid and step_id from t_task
  * split mcore queue so that each site has one
  * changed to set parent_tid=taskid when no parent
  * changed the initial task status from submit to waiting 
  * fixed to set countryGroup for JEDI
  * fixed to set priorities in t_task when tasks are inserted
  * fixed to set errorcode/diag to permerge jobs when merge job failed
  * fixed jobDefinitonID for JEDI jobs
  * changed finished/partial to done/finished as task status
  * added allowFAX
  * added changeTaskPriorityPanda
  * added isDirectIO to SiteSpec
  * fixed to use FQAN when inserting tasks
  * fixed not to close top-level datasets when upstream JEDI job failed 
  * fixed reassignSite.py
  * fixed for JEDI+destSE
  * added protection against RucioFileCatalog error 
  * added protection against task duplication using t_task
  * chanted to use dq2 for Lucille_CE
  * fixed for log+ObjectStore
  * sending info of ObjectStore to the pilot
  * added retry and merge mechanisms for event service
  * added a protection against un-formatted destinationDBlock
  * changed to register new version before deleting pre-merged files
  * added a protection against FileCatalogUnknownFactory
  * fixed the brokerage for nightlies
  * fixed insertTaskParam for uniqueTaskName=False 
  * fixed truncation of priority in the brokerage when getting # of jobs
  * added getRetryHistoryJEDI
  * fixed dispatcher for glexec=test and HC
  * fixed updateUnmergedDataset to increment nFilesTobeUsed
  * fixed error message for duplicated task submission
  * fixed killTask.py not to kill transferring jobs when noRunning is used
  * fixed brokerage for evtest
  * fixed for new columns in JEDI_Events
  * added I/F for incexec
  * removed priority boost for det-tile	
  * changed to work with ATLAS_DEFT.T_TASK
  * added a protection for missing email address in DQ2 
  * changed for schedconfig.glexec=test
  * added config param for proxy cache
  * changed to update users.email
  * added a protection not to send notification when updating Notifier
  * added a protection against duplicated task insertion
  * fixed sendCommand for permission check
  * added merge info to TaskDetails
  * ignore inputFileType for panda.um
  * fixed for bookkeeping based on JEDI 
  * added ProxyCache stuff
  * increased priorities for det-tile
  * fixed file callback to connect multiple MB backends
  * fixed archiveJob to propagate the result of downstream jobs to JEDI
  * removed direct LFC dependence
  * fixed brokerage for analysis with nightlies
  * changed checkBanUser to update DN
  * added jobSubStatus
  * added getCmtConfigList
  * fixed AdderGen not to repeat subscriptions
  * cleanup for JEDI merging
  * fixed archiveJob to delete downstream jobs in small chunks
  * changed for JEDI merging
  * fixed error message in TA 
  * changed pilotRetry to propagate changes to JEDI
  * fixed propagateResultToJEDI for finalizePendingJobs
  * improved not to retry lost files in JEDI
  * opened addTask for users
  * add capability to ban users in addTask
  * changed the brokerge to use maxwdir instead of maxinputsize
  * added finishTaskJEDI
  * changed the brokerage for nightlies
  * introduced WrappedCursor
  * added MySQL support

* 0.0.20 (10/21/2013)
  * added killTaskJEDI	
  * removed constraint from the brokerage so that many input jobs can go to T2
  * added HIMEM to hospital
  * improved the brokerage to use mintime
  * changed add.py not to run around log rotate 	
  * dusted getNUserJobs off	
  * fixed getScriptOfflineRunning to set cmtconfig	
  * fixed resetJob for anal jobs
  * changed not to pin input data when --useShortLivedReplicas is used
  * changed broekrage not to use LOCALGROUPTAPE
  * fixed link to new pandamon in Notifier
  * modified copyArchive for JEDI reassignment
  * removed RETURNING from propagateResultToJEDI	
  * changed the brokerage to use maxmemory
  * changed TaskBuffer to give high prio to hammercloud-fax 	
  * removed muliCloudFactor from the brokerage	
  * added uploadLog	
  * added minmemory,maxmemory,mintime
  * changed available disk check in the brokerage
  * added insertTask and killTask
  * using graceful in logrotation 
  * removed split T1
  * changed space limit in TA to take MC share into account
  * added certificate check in fileCallbackListener
  * reduced the number of threads in Adder to avoid crash caused by DQ2 API
  * fixed AdderAtlas to give up DQDatasetExistsException	
  * fixed callbach.sh for dashboard	
  * merging branches/sl6:r15320 through r16058 

* 0.0.19 (7/8/2013)
  * tagged for SLC6
  * added docstring to Client.py
  * fixed getJobs for priority cap
  * fixed brokerage for ROOT
  * fixed handshake to JEDI
  * updating nFilesOnHold
  * removed the requorement to run jobs at T1 for MCORE jobs
  * added JEDI stuff

* 0.0.18 (7/2/2013)
  * tagged for JEDI
  * fixed datriHandler for SLC6
  * improved getLFNsInUseForAnal
  * fixed getScriptOfflineRunning for athenaMP
  * fixed dispatcher so that install jobs can run on sites with status=test
  * fixed for ANALY_BNL_SHORT and ANALY_BNL_LONG
  * included group analysis jobs in priority massage 
  * removed priority boost for group analysis jobs
  * fixed brokerage to respect preset computingSite even for too many input
    jobs in cloud with negative t1weight

* 0.0.17 (4/27/2013)
  * giving a higher prio to install jobs
  * split runRebro from copyArchived
  * fixed retryInActive to reset file status 
  * modified dispatcher to send prodSourceLabel for getJob
  * changed ATLAS_PANDALOG.USERS_ID_SEQ to ATLAS_PANDAMETA.USERS_ID_SEQ
  * added TaskMonitor link to email notifications
  * changed getJob() to allow the prod/analy pilot to get installation jobs
  * fixed retryJobsInActive
  * fixed datasetManager to delete sub from foreign T1 instead of home T1
  * improved getDisInUseForAnal
  * added boostUser
  * improved fairshare to support per-cloud shares
  * changed Setupper to register both DATADISK and PRODDISK as locations for sub
  * changed job/task brokerages not to check DBR with DQ2 at CVMFS sites
  * changed the brokerage to skip release checks for releases=ANY
  * fixed for site.priorityoffset
  * fixed T2 cleanup to check if there is active subscription
  * fixed brokerage and copyArchive for RU
  * changed insertNewJob not to insert metadata when it is empty
  * fixed killUser to kill jobs gradually
  * fixed Setupper to make dis for pin at MCP sites in ND cloud
  * fixed Setupper to take cloudconfig.tier1se into account for dis subscriptions
  * set a limit on G/U in the brokerage
  * sending more info in PD2P logging
  * fixed LFC lookup in the brokerage
  * changed PD2P to be triggered by the second job
  * removed multiCloudFactor from the brokerage for NL
  * added a protection to updateJobStatus to prevent holding->transferring
  * fixed getUserParameter to insert new row if the user is missing
  * fixed Setupper to trigger prestaging when sites with multi-endpoints use TAPE
  * put all info to ErrorDiag in the brokerage
  * added modificationTime constraint to URL sent to the user by Notifier
  * introduced ProcessLimiter
  * changed TA to shorten retry interval after refreshing replica info
  * skipping file availability check for log datasets in TA
  * using cloudconfig.tier1SE to count files at T1
  * setting scope only for ATLAS
  * improved the task brokerage to check datasets with fewer replicas first
  * set limit on the number of IDs to be sent to the logger for reassign/killJobs
  * removed LFC lookup from TA
  * changed PD2P to use secondary share
  * fixed to use correct DQ2 site ID for pinning at sites with multi-endpoints
  * modified to send scopes for output files to the pilot
  * added changeJobPriorities
  * using DATADISK for MCP T1 input at all T1s except US
  * added filespec.scope
  * reducing lifetime of dis when corresponding jobs finished and some of them failed
  * improved the brokerage to count the number of running jobs per processingType
  * using transferringlimit in the brokerage
  * fixed the bulk OK file lookup again for unique ddm endpoint sites
  * reduced interval of PandaMover reattempts to 15min from 3h
  * fixed the bulk OK file lookup in the brokerge for multiple ddm endpoints
  * increased the number of PandaMover channels to 15
  * using DATADISK for MCP T1 input at CERN
  * using a default fairshare defined per cloud if T2 doesn't define share
  * added a protection against overwriting of dataset status by datasetMgr
  * implemented a nested fairshare management mechanism
  * fixed the brokerage message when release is missing for repro
  * fixed TA since replicas at T1 non DATADISK prevented T2 replicas from being used
  * using DATADISK for MCP T1 input at ND,ES,DE,NL,TW
  * added a patch for MWT2 to associate MWT2_DATADISK in TA
  * allowed wildcards in cloudconfig.tier1SE
  * fixed Merger for standalone ROOT
  * fixed Closer to trigger merging for cancelled jobs 
  * fixed Setupper to pin DBR as well
  * added a protection to Setupper for file lost after job submission
  * fixed getHighestPrioJobStatPerPG for group queue
  * added group queue to all clouds
  * added FOR UPDATE when getting jobdefID for users
  * removed hard-coded FZK-LCG2_DATATAPE removal in TA
  * set activity=Production to TA subscriptions
  * fixed weight reduction in TA for no input tasks
  * fixed the brokerage to send message to logger for too many transferring's
  * fixed wrong error message in TA when open dataset is incomplete
  * updated TA to use a special weight reduction when only TAPE is available
  * removed selector from fileCallbackListener 
  * fixed for TMPDISK
  * fixed Setupper to scan T2 LFC per LFC host instead of per SE
  * fixed Setupper to use correct location when pinning dis at foreign T1
  * fixed sitemapper to allow multiple DQ2 site IDs to use the same token
  * added DQ2 registration time to SLS
  * fixed vomsrenew.sh to check certificate and proxy lifetime
  * fixed file-check in the brokerage for BNL@non-US 
  * fixed brokerage not to overwrite file's destSE for destSE=local
  * introduced mcore queue in PG
  * added iscvmfs to SiteSpec

* 0.0.16 (8/29/2012)
  * changed Setupper to make sub when data is available only at T2
  * changed Setupper to make sub when data is missing at T1 
  * change TA to pin input and skip replicas with ToBeDeleted
  * using share=secondary for non T2-close-source PD2P  
  * added useWebCache() to Client
  * fixed getJobStatistics not to read archived via http by default
  * fixed Adder2 to skip destSE check for ddm=local 
  * fixed LFCclient to randomly resolve DNS alias for LFC host
  * added makeSlsXml
  * patched smtplib.stderr to send debug info to logger
  * added 32/64 to getScriptOfflineRunning
  * changed JOBSARCHIVED4_MODTIME_IDX hint
  * enabled maxtime check for analysis brokerage
  * fixed to check T2 files when get reassigned
  * removed hints related to JOBSACTIVE4_JOBSTATUS_IDX
  * fixed setOK to check map
  * fixed resetDefinedJob for for recordStatusChange
  * fixed updateJobStatus not to reset modificationTime of holding jobs
  * fixed file check not to use TAPE replicas when T1 is used as T2
  * disabled release check for CERN-RELEASE
  * enabled release check for CERN
  * removed EVNT from PD2P
  * removed the higher priority to phys-higgs
  * added _LONG as a suffix of hospital queue
  * fixed queryLastFilesInDataset agains missing jobs which are still in fileDB
  * added setPriority.py
  * fixed updateJobStatus for endTime
  * updated the brokerage log to have timestamp
  * updated the brokerage to take maxtime into account
  * updated file-level callback
  * added Job Status Monitor
  * added --killUserJobs to killJob.py
  * added reliability-based brokerage for analysis jobs
  * fixed getDestSE to look into ARCH for sub datasets for failed log files
  * fixed rebrokerage when orig replica is set to ToBeDeleted
  * temporally gave a higher priority to phys-higgs for ICHEP2012
  * added code=91 to allow prod role to kill user jobs gracefully 
  * check LFC every hour for high prio transferring jobs
  * fixed datasetManager for T2 cleanup by recognizing T1 PRODDISK correctly
  * delete sub from PRODDISK except US clous 
  * added protection to ReBroker against redundant comma in excludedSite 
  * added fatal errors for datri in Adder2
  * fixed Adder2 for missing src in schedconfig for analysis with destSE
  * changed brokeage to make a chunk for each diskCount/memory
  * added RbLauncher to run ReBroker in grid env
  * added more message to Finisher 
  * fixed Adder2 for failed jobs to add files to sub
  * reduced the number of add.py
  * modified getHighestPrioJobStat to calculate per PG
  * added --noRunning to killTask
  * fixed insertSandboxInfo to use real file size
  * added checkSandboxFile
  * fixed brokerage for nightlies
  * extracting crc from input sandbox in putFile
  * added changes for debug mode
  * setting prestage sites with PandaMover dynamically
  * removed BNL_ATLAS_1 from SiteMapper
  * removed FILESTABLE4_DATASET_IDX
  * added more info to putFile
  * optimized getDisInUseForAnal in TB
  * fixed TA to ignore non-DATADISK replicas at T1 
  * fixed brokerage for preassigned repro jobs
  * fixed dataset update timing check in Notifier 
  * rixed zero suppression with wildcard in brokerage
  * fixed rebro to set the same specialHandling to build since new build may have different specialHandling
  * removed old hints
  * fixed DataServiceUtils to return an empty map when DQ2Map is set
  * using FOR UPDATE in lockJobForReBrokerage 
  * added more debug INFO to Setupper
  * fixed DBProxy not to freeze top datasets for HC when build failed
  * fixed anal brokerage to take # of defined jobs into account
  * setting RUCIO_ACCOUNT and RUCIO_APPID
  * pin dis for foreign T2s in US cloud
  * removed special treatment for BNL from Adder
  * fixed the brokerage to get hospital queues automatically
  * updated brokerage to use coreCount
  * fixed Closer not to freeze any HC datasets
  * fixed Adder since Register2 gives DatasetExist error when it got deleted 
  * enabled cap based on priority for CERN
  * not reset retried jobs in Watcher
  * check attemprNr in retryJob
  * added double quotas to all params in getScriptOfflineRunning
  * added jobMetrics
  * added a protection against non-integer PandaID in peekJob
  * changed to update only changed attributes in job tables
  * fixed runMerge not to be stopped due to a single dataset error
  * added debug message for execution time of DQ2(+LFC) registration  
  * fixed storeJob to reset changed attribute list
  * disabled beyond-pledge for HC jobs
  * changed to update only changed attributes in filesTable4
  * added nOutputDataFiles and outputFileBytes to job tables
  * modified getScriptOfflineRunning to use parallel transfers
  * removed shadow lookup in Adder
  * disabled sub for computingSite=destinationSE
  * added getScriptOfflineRunning
  * added retry to Cassandra operations
  * changed killing with group prod role not to be case-sensitive
  * added getDis/LFNsInUseForAnal
  * added getPledgeResourceRatio to TB
  * added Cassandra file cache
  * added TAG support in EventPicker 
  * added countGuidsClient
  * using SCRIPT_NAME in panda.py
  * removed _shadow creation in ReBroker
  * fixed queryLastFilesInDataset for the fileTable change
  * remove deleting datasets from the Datasets table
  * sending error log to the logger when TA cannot find dataset in DQ2
  * sending fsize and checksum to the pilot
  * added modificationTime<=CURRENT in getFilesInUseForAnal
  * added hint when deleting rows from Datasets 
  * making larger subs by sorting jobs by site
  * instantiating dq2api in each thread
  * added hint to use 11g cashing
  * removed constraint in TA to consider T1 and T2 equally
  * increased the lifetime of the proxy to 96h
  * fixed TA to select candidate T2s correctly
  * getting shadow info from filesTable
  * added vomsrenew.sh
  * fixed TA to count the number of files at US T2
  * check attmptNr
  * fixed for non-MC/DATA space at split T1
  * fixed TA to check completeness at T2 
  * use correct locations for GEN dis when jobs directly go to T2
  * added protection to Adder2 against sites disappearance from schedconfig
  * added preferential analysis brokerage based on countryGroup
  * added more verbose message in Adder
  * Mikhail Titov updated datriHandler
  * fixed cloudlist to skip None
  * added getJobStatisticsPerUserSite
  * added 64bit in copyROOT
  * avoid priority reduction for merge jobs
  * use <= for maxDiskCount in getJob
  * fixed rebrokerage for --destSE
  * updated rebrokerage to be triggered 3 hours after the site is blacklisted
  * set maxAttempt to allow users to disable auto retry
  * changed global file map to local in brokerage
  * fixed Adder2 to use proper destination for token=TAPE when running at T1 as T2
  * updated killJob to take group prod role into account
  * updated brokerage to take priorities into account for prod jobs
  * using native DQ2 call in ToA
  * modified brokerage to do bulk LFC lookup per site  
  * fixed brokerage_util to do LFC lookup per 1000 files instead of 100 files
  * fixed brokerageErrorDiag for repro + missingRel 
  * fixed port of pandamon in email notification
  * fixed brokerageErrorDiag for useT2 + repro
  * set replica pin lifetime before deleting from T2
  * improved brokerage error diag
  * cleaned the brokerage for hospital queues
  * use 0 when memory=0 in one of online sites with the same siteID
  * fixed the brokerage to use RAL-LCG2_H​IME as UK T1
  * touch input sandbox when tried to be overwritten
  * permit overwriting of input sandbox
  * reject limited proxy
  * added priority boost for gangarobot-pft
  * fixed getCriteria for aggregated sites
  * fixed brokerage for group=any:0%
  * fixed brokerage more for type=any:0%
  * fixed brokerage to take zero shares into account
  * fixed getCriteriaForProdShare for zero shares
  * added minPriority to Client.getJobStatisticsPerSite
  * using MV in getJobStatisticsWithLabel
  * added fairshare to getJob
  * fixed retryJob not to change the name of lib.tgz for ptest
  * fixed retryJob not to retry buildJob to keep the PandaID order
  * fixed TB to give higher prio to buildJob with prodRole  
  * fixed Merger to use the largest SN for merged files
  * fixed queryLastFilesInDataset to ignore merged files 
  * fixed brokerageErrorDiag for non missing release errors
  * added tmpwatch.py	
  * changed hint in getJobs
  * fixed updateProdDBUpdateTime for pending jobs
  * fixed brokerage to accept test sites for prod_test jobs
  * changed getJobs for test pilots to get gangarobot jobs
  * setup glite in TaLuncher
  * added lock in lockDatasets
  * added version check in Merger to avoid duplicating merge jobs
  * changed Merger to fail when container name is too long
  * use lockJobsForReassign for reassign in copyArchive
  * use native DQ2 in copyArchive and datasetMgr
  * use python2.5 for copyArchive and prio-mgr
  * use native DQ2 in Setupper 
  * fixed guid generation for user's log
  * introduced 2 staged submission for prod jobs 
  * using T2 in TA
  * using materialized view get getJobStatistics family
  * updated Merger to put log files of merge jobs to a separate container
  * fixed Merger for --transferredDS 
  * enabled rebrokerage for processingType=ganga
  * updated Adder for unique constraint error
  * added copyROOT
  * updated Adder to immediately go to failed when subscription failures 
  * disabled prio boost for gangarobot derivatives
  * added protection to TA against undefined maxinputsize
  * updated TA and brokerage to use T2 datasets in prod
  * updated for DQ2 client 0.1.37

* 0.0.15 (11/07/2011)
  * removed redundant freshness checks in getSN
  * changed hint in getSerialNumber
  * randomized job order in adder
  * decreased the number of adder processes
  * added more tight constraint to getJobStatistics family
  * reduced prio by 10 for pilot-retry jobs
  * increased the factor of the RW limit to 8000
  * updated Merger for --mexec
  * modified rebroekrage to send brokerage log
  * modified brokerage to send user's countryGroup and nJobs to logger 
  * added a protection to httpd.conf for interesting panda.py
  * not attach attemptNr to lib.tgz for rc_test+buildJob
  * fixed parentID for retryJob with new PandaID
  * randomized the order of site check in analysis brokerage 
  * added --killOwnProdJobs to killJob.py and killJobsInTask.py
  * fixed brokerage to require cache=None for release check 
  * pinning input datasets
  * added limitation of exe/pilotErrorDiags in JD
  * fixed short->long mapping in retryJob
  * generates new PandaID for pilot-retried job 
  * using negative errorcode for pilot-retry
  * added invalid character check to DDM
  * fixed the brokerage for --transferredDS

* 0.0.14 (10/11/2011)
  * fixed TaskAssigner for MCshare=0
  * updated brokerage to consider priorities for analysis jobs
  * fixed brokerage for BNL_CVMFS_1
  * modified managed pilots to get prod_test as well
  * call addShadow even if DaTRI failed
  * fixed the error message of location registration in Setupper
  * modified ReBroker for server-side retry
  * reverted the brokerage change
  * changed brokerage to skip sites with memory=0 for analysis with memory
  * increaded MaxClients
  * use DQ2 for foreign T2 in US cloud
  * use IN2P3-CC and IN2P3-CC_SGE_VL as FR T1 in brokerage
  * unset commandToPilot for jobs reassigned by rebrokerage
  * added retryJobsInActive
  * added --maxJobs and --running to killJobLowPrio.py
  * added killJobLowPrio.py
  * fixed killJob
  * simplified anal_finalizer
  * added SiteSpec.lfcregister
  * added getAttr
  * keep failed analysis jobs in Active until all jobs finished

* 0.0.13 (8/30/2011)
  * fixed Adder2.removeUnmerged to catch DQ2 errors correctly
  * using subType in datasetManager
  * filling datasets.subtype
  * added protection against too large inputFileBytes
  * removed CN=Robot: from DN
  * added hint to DBProxy.getLockDatasets
  * reduced the number of table scan in datasetMgr and runMerge
  * fixed brokerage not to count jobs for usermerge or pandamover
  * changed brokerage to use ANALY_CERN_XROOTD and not to use ANALY_CERN
  * added Forker to add.py
  * updated dispatcher to send taskID
  * using schedconfig.multicloud
  * fixed brokerage for test sites
  * fixed brokerage not to count jobs for HC
  * fixed rebrokerage for CERN TMP
  * updated the brokerage to stop assigning prod jobs to sites which have many transferring
  * added jobdefID to libDS in ReBrokerage 
  * disabled short -> long for HC
  * fixed SiteMapper to respect online even if another queue is not online
  * put attempt number to output file name in Merger
  * changed = to == in redundant messages
  * job-chaining for ptest+prun
  * added initLogger to Notifier
  * removed redundant suffix from DN for DaTRI request in EventPicker
  * added more message in EventPicker for DaTRI request
  * changed Notifier to non-thread
  * fixed Notifier to take into account old jobs in Arch
  * implemented new PD2P scheme using MoU and close sites
  * increased the number of concurrent Mergers
  * incrementing Datasets.currentfile only for the first failed job
  * fixed Watcher to append attemptNr when sent->activated
  * fixed resetDefJob
  * limited the number of jobs with the same GEN dis
  * fixed EventPicker to take input files into account
  * fixed Merger to use .tgz for text merging
  * added EventPicker
  * added statusmodtime to SiteSpec
  * updated Merger for runDir
  * updated rebrokerage to take --cloud into account
  * added tags into PD2P logging
  * updated Merger for mergeScript
  * fixed getFilesInUseForAnal to skip NULL dis datasets
  * updated analy_brokerage to use memory size
  * added cmtconfig to broker logging
  * enabled cross-cloud for US in PD2P 
  * enabled banUser in storeJobs
  * enabled role-check in submitJobs
  * added WrappedPickle to avoid deserializing insecure objects
  * added banUser to storeJob
  * added prodSourceLabel check to UserIF

* 0.0.12 (6/13/2011)
  * fixed Merger for --useContElement
  * fixed inputFileProject extraction for wildcard-uses
  * using basename in Utils methods
  * fixed fetchLog to disallow chdir
  * fixed panda.py to disallow unexpected methods
  * added getVomsAttr
  * updated getJob to decompose CERN-XYZ to CERN-PROD+processingType
  * updated the brokerage to use installedsw.cmtConfig
  * use MoU share for T1 PD2P
  * added getNumPilots
  * added prodSourceLabel=ssc as user's label
  * added --prodSourceLabel to killUser
  * fixed archiveJob for failed jobs with multiple dis
  * fixed Setupper to store GEN dis
  * disabled release check in the brokerage for x86_64-slc5-gcc43
  * implemented aggressive cleaning for PRODDISK
  * added priority boost for gangarobot
  * updated T2 cleanup to use grace_period='00:00:00' 
  * cleanup copyArchive
  * changed analysis brokerage to use nRunning(max in last 24h)
  * increased # of active subscriptions to 2 in PD2P
  * added nRunning calculator to add.py
  * disabled priority reduction for merge jods
  * sending analysis brokerage info to logger
  * updated PD2P not to check provenance since group datasets have mc*/data* 
  * disabled PD2P to CERN-PROD_EOSDATADISK
  * added checkMergeGenerationStatus
  * enforce LFN-lookup to trigger getting replica map when reassigned
  * fixed brokerge for test jobs at test sites
  * use release matching for T2s in CERN cloud
  * skip release check for CERN and ND
  * set correct info to brokerageErrorDiag 
  * send jobs to waiting when release/cache is missing
  * remove '' for |pilotOwners|
  * put cloud-boundary back to US
  * use SourcesPolicy.ALL_SOURCES for PD2P subscriptions
  * improved PD2P logger
  * included CERN to trigger PD2P 
  * fixed typo in PD2P skip message
  * fixed zero-division in PD2P
  * enabled T1-T1 in PD2P

* 0.0.11 (4/18/2011)
  * fixed getExpressJobs
  * use c-t-s for all files in merge jobs
  * modified runMerger to kill old process
  * disable Initializer when nDBConnection is 0
  * increased max attempt for rebrokerage to 5
  * changed the rebrokerage interval to 24h
  * skip init for jobDispather,dataService,userIF when nCon=0
  * added parameters in email notification
  * ignore LOCALGROUPDISK in PD2P 
  * fixed auto type detection of Merger for THIST
  * use IN2P3-CC_VL for too many input or high prio jobs
  * gave T1 weight to IN2P3-CC_VL
  * added protection to Adder2 against DQ2 failure for jumbo datasets
  * updated Adder2 to avoid making DaTRI request for unmerged files
  * added protection against generating multiple Mergers for --individualOutDS
  * updated brokerage to give T1 weight to NIKHEF for repro jobs
  * fixed Merger for lib.tgz
  * added automatic merge type detection to Merger
  * updated Closer to redirect logging to parent as it doesn't work in nested threads
  * changed parameter convention for Merger
  * added merge job generation
  * set secondary for TA subscription
  * use TAIWAN-LCG2_HOTDISK for TW HOTDISK
  * disabled PD2P for ESD
  * set file.dispDBlock even if they are already available at the site
  * send jobDefID and cloud to the pilot
  * updated Setupper/Adder2 for T1 used as T2
  * set destDBlockToken to DATADISK
  * using home cloud to skip release check in the brokerage
  * reassign stuck T2 evgensimul more frequently
  * enabled release/cache check for US
  * using nRunning(cloud) in brokerage for multi-cloud
  * added fileGUID to updateInFilesReturnPandaIDs for file-level callback 
  * set source to _subs for all clouds
  * using DQ2 API directly in Adder 
  * added nInputDataFiles,inputFileType,inputFileProject,inputFileBytes
  * add hacks again to TA and Setupper for split T1
  * added EventLookup to PD2P
  * updated SiteMapper for multi-cloud
  * removed hacks from TA and Setupper for split T1
  * added forceOpt to runReBrokerage
  * fixed PD2P not to make sub when dataset is being deleted
  * changed PD2P not to send ESD to EOS
  * added a hint to getPandaIDsForProdDB to enforce function index
  * added comment_ to SiteSpec
  * put hacks back to TA and Setupper for split T1 which uses NIKHEF as src 
  * set hidden metadata to _dis and _sub
  * removed REGEXP from Datasets cleanup
  * enabled rebrokerage for ganga-rbtest
  * fixed ReBroker for EOS
  * fixed ReBroker to add _shadow
  * use DATADISK for all PD2P subscriptions
  * close user datasets in container
  * set lifetime for dis and sub datasets
  * added --jobsetID to killUser.py
  * added protection against missing argument for jobID/jobsetID to killUser.py
  * trigger PD2P for EOS when nUsed >= 3  
  * updated brokerage to take transferType into account
  * update modificationTime when going to Archived4
  * disabled extra replica making in PD2P
  * trigger PD2P for EOS when nUsed >= 2
  * added testG4sim16.py and testEvgen16.py
  * use diskThr=max(5%,3TB)-diskSize in PD2P
  * added killJobsInTask
  * set disk threshold in PD2P to 5GB
  * updated PD2P so that any analysis job using data makes subscriptions to CERN EOS
  * set specialHandling=rebro when reassigned by rebrokerage 
  * fixed DQ2 ID conversion in PD2P for EOS
  * check free disk size in PD2P using DQ2.queryStorageUsage
  * use function index in getPandaIDsForProdDB 
  * reduced the number of rotated logs
  * use cernmx.cern.ch
  * added getLockDatasets
  * added the number of succeeded jobs to the subject of Notification
  * added pd2p logging
  * added deleteJobs.py
  * split arch procedure to another cron
  * call taskbuffer.Initializer in forkSetupper.py to acquire Oracle environment handle correctly
  * use truncated DN when setting dataset owner 
  * reassign evgen/simul with active state at T1 more aggressively
  * made SQLDumper iterable
  * added SQLDumper
  * added reassignTask
  * use getFullJobStatus in Notifier since some jobs can go to ARCH before notification
  * seprate retry for Notifier
  * added retry to Notifier when failing to send notifications
  * express jobs
  * make new dis datasets even if files are already available at T2 
  * short/long mapping for ANALY_LYON-T2
  * updated PD2P to use a negative weight based on the number of subs
  * ignore hidden datasets in PD2P
  * don't use modTime index on jobs_ARCH
  * set/increment nUsed in PD2P
  * use LFN for WN-level matchmaking
  * ignore datasets with provenance=GP for PD2P
  * don't reuse the same site in a single PD2P cycle 
  * fixed brokerage to send warning when cache is missing
  * removed redundant holding for prod jobs in Watcher
  * more fix to SetUpper for rc_test
  * not reset holding analysis jobs when stateChangeTime=modTime
  * set stateChangeTime when job goes to holding for finished/failed
  * job chain for rc_test + gangarobot-rctest
  * added archivelogs
  * set tobeclosed to sub datasets of failed downstream jobs
  * rctest -> rc_test
  * reduced time interval to reassign waiting jobs to 30min
  * enabled user-triggered rebrokerage
  * send currentPriority in dispatcher
  * set localpool to specialHandling when beyond-pledge pilot got the job
  * fixed makeSub in TA for getAva change
  * added random sleep for Finisher in copyArchive
  * improved del in copyArchive to avoid redundant deletion
  * increased timelimit for copyArchive
  * added auto rebrokerage to copyArchive
  * report new PandaID to taskBufferErrorDiag when rebrokered
  * check procesingType in rebrokerage 
  * added code=8 to killJob for rebrokerage
  * first implementation of auto rebrokerage
  * added getCachePrefixes 
  * removed apostrophes from prodUserName
  * fixed useNiotifier in Closer for completed sub datasets
  * changed queryLastFilesInDataset to use MAX(lfn)
  * improved the space shortage message in TA
  * don't check missing files with LFC when site is already set
  * added -9 to killTask
  * added forceKill for prod jobs 
  * changed the brokerage to use CERN-PROD_EOSDATADISK as the dest for CERN-EOS jobs  
  * added enforce to Activator
  * changes for merge/unmerge jobs
  * rctest
  * deleteStalledJobs
  * removed hacks for last_insert_id of InnoDB
  * allowOtherCountry
  * updated datriHandler to prevent false http-requests
  * added a hint to getJobIDsInTimeRange against jobsActive4
  * added a hint to getJobIDsInTimeRange against jobsArchived4
  * changed hint in DBProxy.updateTransferStatus
  * changing TRF URL from BNL to CERN on the server side
  * fixed error message in brokerage for sites with status!=brokeroff
  * fixed brokerage for release check when schedconfig.rel != ''
  * changed countryGroup=ustlas to us
  * ignore gangarobot family in PD2P 
  * disabled priority decreasing for HC jobs
  * use installedSW for base-release matching for analysis
  * $GROUPJOBSN
  * added getSerialNumberForGroupJob
  * use jobsetID in Notifier
  * use max memory/inputsize for each site
  * set jobsetID for ptest
  * changes for output container and short LFN for analysis

* 0.0.10 (8/2/2010)
  * tagged for output container and short LFN for analysis
  * added setCloudTaskByUser
  * get list of PD2P clouds dynamically
  * send transferType to the pilot
  * imposed a size limit on uploaded files by users
  * fixed the task brokerage to take maxDiskCount into account
  * added a protection againt empty jobParameters only for new jobs
  * fixed PD2P to remove the cloud boundary when counting nSites
  * disable brokerage for gangarobot
  * ignore HC and group jobs in PD2P
  * fixed PD2P to take non-PD2P sites into account when checking comp/incomp
  * fixed AtlasRelese for PD2P
  * enabled WN brokerage for ANALY_GLASGOW
  * updated Adder for --destSE=multiSites
  * use Data Brokering fr PD2P
  * change MWT2_UC_DATADISK to MWT2_DATADISK in PD2P
  * delete replicas from T2 when locations != []
  * protection against meta/para=None in peekJob
  * kill ITB_INTEGRATION jobs in sent status
  * batchID
  * ignore dis/sub in PD2P
  * dispatchDBlockTokenForOut
  * added banUser.py and made --jobID optional in killUser.py 
  * set activity='Data Consolidation' and acl_alias='secondary' to PD2P subscriptions
  * check replica at T1 in PD2P
  * added getActiveDatasets
  * don't move RAW,HITS,RDO by PD2P
  * allow prod proxy to kill anal jobs with 2 or 4
  * added PD2P
  * regard found=None as an incomplete replica
  * invoke listFileReplicasBySites only for incomplete sites in TA
  * fixed re-brokerage
  * fixed used file check for cancelled jobs
  * increased wait interval for reconnection in connection pool
  * updated ConBridge to kill child when connection failure
  * changed URL of panda mover trf
  * added a protection against method execution failure in panda.py
  * set dataset status for DaTRI requests
  * ignore DaTRI failure for duplicated requests
  * use DQ2 for email extraction
  * added -9 to killJob.py 
  * added killUser.py
  * added alias to httpd.conf for trf URL  
  * changed reading order in getPandIDsWithJobID to avoid missing jobs
  * set taskBufferErrorDiag when running jobs are killed
  * prevent prod proxy from killing analysis jobs
  * added priority massager
  * added NG words to Notifier
  * avoid sending DaTRI requests for failed jobs
  * fixed replica registration for --destSE
  * set type in datriHandler for analysis system
  * testpanda -> panda
  * introduced datriHandler
  * delete sub datasets from EGEE T2 when callback is received
  * set REMOTE_HOST to creationHost
  * increased priority boost for activated jobs
  * delete cancelled from jobsDefined4
  * added boostPrio.py
  * added cvs,svn,grid,librarian to NG words
  * True/False for schedconfig.validation
  * added admin to NG words for Notifier
  * added cancelled state

* 0.0.9 (4/13/2010)
  * increased the subscription limit to 600 in TA
  * protection against reassigning analysis jobs
  * enabled cache-matching brokerage for all EGEE clouds
  * enabled cache-matching brokerage for NL/FR
  * added a protection for containers composed of multiple datasets
  * added processingType to runBrokerage for HC
  * doesn't check release matching for CERN
  * cache-matching in the brokerage for DE 
  * added getHighestPrioJobStat
  * changed weight for the task brokerage to use RW instead of fullRW
  * fixed getFilesInUseForAnal for --individualOutDS
  * added getQueuedAnalJobs
  * updated brokerage to assign one prod_test job to a site 
  * disable prod role for non-group activity
  * use maxinputsize in the brokerage
  * added schedconfig stuff to template
  * removed cx_Oracle from FileSpec
  * removed MySQLdb from broker_utils
  * added maxinputsize
  * modified xyzCacheDB to take a list of siteIDs
  * suppressed warning messages in dashboard 
 
* 0.0.8 (2/2/2010)
  * tagging for SLC5 migration
  * added hostname matching for T3 pilots
  * use listFileReplicasBySites in TA
  * added checkFilesWithCacheDB
  * changed the default cmtconfig to SL4 for analysis in brokerage
  * updated the brokerage to allow slc4 jobs on slc5 sites
  * added killTask.py
  * added addFilesToCacheDB and flushCacheDB
  * modified dispatcher to accept service proxy
  * added WN-level file matching to getJob 
  * added MemProxy
  * fixed brokerage to skip release/cache matching for ND
  * use all source locations for dis
  * use long hint for queryDatasetWithMap 
  * added /Engage/LBNE/Role=pilot to acceptable roles
  * added analy_test to getJob for test pilots
  * use poffset regardless of accesscontrol
  * removed / from FQAN check in allowedgroups
  * limit the max number of files in sub dataset
  * use fasttrack only for evgen/simul
  * added cleanup in updateSiteData
  * added chdir to LFC 
  * added chdir for dq2 and fork
  * removed logging updateJob/getJob from dispatcher
  * use averaged updateJob/getJob 
  * ignore test when summing SiteData
  * don't update SiteData when logrotate is running
  * randomized the order of sites in updateSiteData to avoid concatenation
  * fixed checkSitesWithCache	
  * multi-threads in adder.py
  * count number of updateJob/getJob in add.py
  * use taskBuffer in add.py for all DB access
  * use fasttrack for all tasktypes and prio>=700
  * use taskBuffer for reassignment in copyArchived
  * set the number of treads to 2 in wsgi daemon
  * set MaxRequestsPerChild
  * enabled KeepAlive for proxy sites
  * check filename FieldStorage when a param is treated as file
  * not delete dis datasets when jobs are reassigned  
  * check useFastCGI before importing flup
  * introduced nDBConForFastCGIWSGI
  * fixed Setupper to re-register location at next attempt when previous was failed
  * changed logLevel in httpd
  * added flag to control verbosity of entry point
  * added FastCGI stuff

* 0.0.7 (11/20/2009)
  * removed verbose message from DBProxyPool 
  * more verbose info to DBProxyPool
  * fixed ReBrokerage to require the same distribution pattern of input datasets
  * set encoded nJobs to taskID for analysis jobs
  * fixed ReBrokerage
  * propagate bad state from dashboard 
  * removed threading in dispatcher and dataservice
  * fixed typo in dashboard access
  * fixed CloudTaskSpec for serialization
  * close non-DQ2 destinationDBlock in Closer
  * use infinite loop in ProxyPool.__init__
  * add random sleep to ConBridge.connect
  * use TaskBuffer instead of DBProxy in copyArchive
  * added querySQLS to DBProxy	
  * use ping for wakeUp
  * degrade message level of child termination in ConBridge
  * added ConBridge for database timeout
  * re-implemented rebrokerage to allow the case where build finished

* 0.0.6 (11/13/2009)
  * destinationSE=local
  * propage failed_transfer from dashboard
  * added activity to subscriptions
  * added cleanup for Datasets table 
  * added workaround for x86_64-slc5-gcc43 
  * removed TO_DATE for Datasets.modificationdate
  * set priority of buildJob back to 2000
  * renamed testpanda.ddm to pandaddm_
  * added /osg/Role=pilot
  * added lower limit for TO_DATE against Datasets table 
  * added protection in JobDispatch against non-proxy pilots
  * added ReBroker
  * removed UAT stuff
  * use long queue in brokerage in addition
  * increased max subjobs in UserIF to 5000
  * send log message from brokerage when disk shortage
  * use ANALY_LONG_BNL_ATLAS for UAT
  * added temporary priority boost for UAT
  * added YY.MM.DD to destinationDBlock of PandaMover
  * skipped release check in brokerage when weight is negative
  * removed T1 constaint on high prio jobs in brokerage only for i686-slc5-gcc43-opt
  * limit matching of cmtconfig=i686-slc5-gcc43-opt to i686-slc5-gcc43-opt jobs only
  * changed brokerage to use only T1 for many input jobs when weight is negative
  * removed computingElement matching in getJob for test jobs 
  * use transtimelo for timeout of analysis transfers
  * fixed for site->siteid in installedSW
  * added protection to _checkRole()
  * use cache version matching for analysis 
  * added 'user' to NG words in Notifier
  * take '_' into account in Closer for new naming convention
  * use onlyNames in dq2.listDatasets
  * changes for destSE
  * changed cmtconfig for slc5 to match to slc4 and slc5
  * set pandamover priorities using original job priorities
  * added HOTDISK to Setupper
  * added PandaMonURL to email notification
  * send email notification to site contact in addition to cloud contact
  * use schedconfig.DN for privilege check in addition to cloudconfig
  * ptest for analy tests 
  * use SARA-MATRIX for all T1 sources
  * more NG words in address finding
  * skip VUID lookup for analysis jobs
  * added getSlimmedFileInfoPandaIDs
  * added a hint for filesTable_ARCH
  * limited modificationTime on filesTable_ARCH queries
  * allowed the pilot to set status for failed input files
  * make subscription for ptest
  * use /atlas for auth of updateFileStatusInDisp 
  * added updateFileStatusInDisp to flag lost files
  * removed double counting of jobs in Notifier
  * updated template
  * changed LogFormat for SLS
  * send prodDBlockToken to the pilot
  * modified Adder to take DQUnknownDatasetException into account
  * make subscriptions for rc_test
  * flagged all missing files in Setupper
  * added jobType to Client.getJobStatisticsPerSite
  * use stage-priority for prestaging
  * updated the brokerage to take input size into account 
  * use cleanUserID in Notifier
  * add copysetup to SiteSpec
  * fixed getCurrentSiteData for analysis
  * use pilotowners for checkRole in dispatcher
  * ignore DBRelease when adding shadow
  * support getJobStatisticsPerSite(countryGroup=None,workingGroup=None)
  * added two more filed to dis datasetname 
  * calculate priority for each workingGroup
  * added finder for email address using phonebook
  * reverted the change in Setupper
  * register location for _sub even when src=dest
  * workingGroup/countryGroup in getJobStatisticsPerSite
  * added getPandaClientVer
  * fixed MailUtils for multiple recipients
  * reuse unknown input files when build failed
  * use T1 in brokerage when too many inputs are required
  * added a timeout to Client
  * set sources of dis for all clouds
  * use MCTAPE for subscriptions
  * added trustIS to runBrokerage
  * added longFormat to listSiteAccess 
  * added set to updateSiteAccess
  * verify workingGroup
  * send email update/request for site access
  * kill old dq2 processes
  * addded updateSiteAccess
  * workingGroup
  * added MailUtils
  * prestaging for MCTAPE
  * set processingType for mover
  * get proxy for each job in getFullJobStatus
  * fixed address-check to trigger xwho
  * introduced NG words in email-adder finding 
  * put size limit in putFile
  * set higher priority for installation mover
  * skip files used by failed/finished jobs in getFilesInUseForAnal
  * removed BNL and old bamboo stuff from Client.py
  * added a hint to updateInFilesReturnPandaIDs
  * added getFilesInUseForAnal
  * set sources for ES
  * added a hint to getJobIDsInTimeRangeLog
  * removed write spaces from md5sum/checksum in peekJobLog

* 0.0.5 (5/15/2009)
  * subtract N*250M from available space in brokerage
  * use tasktype2 for RW recalculation
  * allow transferring in updateJob
  * use job stat per process group in brokerage
  * added prodUserName
  * added validation to test
  * fixed TA
  * use prodUserName for users
  * added nEvents to JD
  * added pilotowners
  * added rc_test
  * added a hint for Datasets.name
  * enabled validatedReleases for all clouds
  * set high priority for production role
  * added realDatasetsIn
  * get empty list of LFNs for empty dataset
  * set modificationTime to ARCH tables
  * fixed getUserParameter
  * added nInputFiles for HC
  * added countryGroup for country share
  * use a hint for filesTable4.dataset
  * fixed lookup for mail addr
  * use PandaMover for US
  * give higher priorities to /atlas/xyz/Role=production
  * set workingGroup when jobs are submitted with prod role
  * fixed peekJobLog
  * replica location lookup for containers
  * fixed broker_util to use proper python
  * use jobParamsTable
  * fixed python path to use 64bit glite
  * fixed for ArchivedDB
  * fixed FQAN extraction for GRST_CONN
  * dispatchDBlockToken
  * converted datetime to str for stateChangeTime
  * use 12hr limit in getJobStatisticsForBamboo
  * use CERN-PROD_DAQ for prestaging when _DATATAPE is not a location
  * ignore token=ATLASDATATAPE when no tape copy
  * pandasrv -> pandaserver
  * set old=False for listDatasetReplicas
  * fixed copyArchived for ArchiveDB
  * added _zStr/_nullAttrs in JobSpec
  * fixed getJobStatisticsForExtIF()
  * fixed for schedID/pilotID
  * removed redundant debug message
  * fixed for Notification
  * input token for mover
  * set NULL for creationHost,AtlasRelease,transformation,homepackage
  * use sequences directly for PandaID and row_ID
  * use SUBCOUNTER_SUBID_SEQ directly
  * added a hint to countFilesWithMap
  * fixed getNUserJobs
  * removed log/cache dirs making
  * put alias to filesTable4 in countFilesWithMap
  * introduced PANDA_URL_MAP
  * suppressed meta in JobSpec
  * error handling in Adder
  * fixed enddate in Notifier
  * use CURRENT_DATE in copyArch
  * added nprestage
  * added startTime/endTime in updateJob
  * validatedreleases and accesscontrol
  * 3 -> 1hour for movers (discarded)
  * added 'IS NULL' to copyArch 
  * added bulk reading for PandaID to copyArch to avoid redundant lookup
  * added a hint to updateOutFilesReturnPandaIDs
  * use Null instead of 'NULL'
  * don't reset jobParameters when reassigned
  * added a hint to all fileTable4+destinationDBlock
  * use JOBSARCHIVED4_MODTIME_IDX
  * addSiteAccess and listSiteAccess
  * hours=1 -> 3 for movers
  * retry in peekJob
  * reconnection in rollback 
  * added hint to queryDatasetWithMap
  * use bind-variables for all queries
  * fixed freezeDS 
  * fixed a duplicated variable in Closer 
  * truncate ddmErrorDiag
  * hint to freezeDS
  * removed deleteFiles in copyArchived
  * not update modTime in copyArchived when peekJob failed
  * container-aware
  * validatedreleases and space check in brokerage
  * added deleteJobSimple
  * use validatedreleases for FR too
  * fixed reassignXYZ
  * use archivedFlag for copy/delete
  * fine lock for reassignRepro 
  * threading for reassignRepro 
  * improved expiration messages
  * failed when input dataset is not found in DQ2
  * debug messages in Setupper
  * added other error codes in rollback

* 0.0.4 (2/23/2009)
  * GSI authentication for pilots
  * tag-based security mechanism for scheduler-pilot-server chain
  * fixed test/add.py to use Oracle instead of MySQL
  * fixed querySQLS for DELETE
  * added panda_server-grid-env.sh
  * merged DB proxies to reduce the number of connections
  * added lock for worker MPM
  * use common write account

* 0.0.3 (2/16/2009)
  * sync to production version

* 0.0.2 (12/18/2008)
  * adjustments for CERN

* 0.0.1 (12/4/2008)
  * first import

 LocalWords:  ConBridge
